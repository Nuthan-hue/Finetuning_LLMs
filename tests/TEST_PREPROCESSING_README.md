# Phase 4 Preprocessing Tests

This directory contains comprehensive test cases for Phase 4: Preprocessing of the autonomous Kaggle competition agent.

## Test Files

### 1. `test_preprocessing_phase.py`
**Unit and integration tests using pytest**

Contains three test classes:

#### `TestPreprocessingAgent`
Unit tests for the PreprocessingAgent class:
- âœ… Agent initialization
- âœ… Code generation for tabular data
- âœ… Code generation for NLP data
- âœ… Code extraction from markdown blocks
- âœ… Code validation
- âœ… Dictionary formatting for prompts

#### `TestPreprocessingPhase`
Integration tests for the full Phase 4 workflow:
- âœ… Skip preprocessing when not needed
- âœ… Execute preprocessing when needed
- âœ… Save generated code to file
- âœ… Handle execution errors gracefully
- âœ… Validate output files created

#### `TestPreprocessingDataQuality`
Tests for data quality after preprocessing:
- âœ… Remove missing values correctly
- âœ… Preserve target column in train only
- âœ… Avoid data leakage (fit on train, transform on test)

### 2. `test_preprocessing_integration.py`
**Manual integration test with real AI code generation**

Four comprehensive tests:
1. **Code Generation** - Test PreprocessingAgent alone
2. **Code Execution** - Execute generated code and verify
3. **Full Phase Integration** - Test with orchestrator context
4. **Skip Logic** - Verify preprocessing skips when not needed

## Running the Tests

### Option 1: Run pytest unit tests (RECOMMENDED)
```bash
# Run all preprocessing tests
pytest tests/test_preprocessing_phase.py -v

# Run specific test class
pytest tests/test_preprocessing_phase.py::TestPreprocessingAgent -v

# Run specific test
pytest tests/test_preprocessing_phase.py::TestPreprocessingAgent::test_agent_initialization -v

# Run with output shown
pytest tests/test_preprocessing_phase.py -v -s
```

### Option 2: Run integration test with real AI
```bash
# This will use actual Gemini API to generate preprocessing code
python tests/test_preprocessing_integration.py
```

**Note**: Integration test requires `GEMINI_API_KEY` in your environment.

## Test Coverage

### What's Tested

#### âœ… PreprocessingAgent
- Initialization with correct parameters
- Code generation for different modalities (tabular, NLP)
- Code extraction from AI responses
- Handling markdown code blocks
- Validation of generated code
- Prompt formatting

#### âœ… Phase 4 Workflow
- Conditional execution based on `needs_preprocessing` flag
- AI code generation
- Code saving to file
- Code execution in isolated namespace
- Output file validation
- Error handling and fallback to raw data
- Context accumulation

#### âœ… Data Quality
- Missing value imputation
- Target column preservation
- Prevention of data leakage
- Categorical encoding
- ID column handling
- Train/test consistency

#### âœ… Edge Cases
- Empty data
- Invalid AI responses
- Execution errors
- Missing output files
- Different data modalities
- Various preprocessing requirements

### What's NOT Tested (Future Work)
- Vision data preprocessing
- Time series data preprocessing
- Audio data preprocessing
- Multi-modal preprocessing
- Custom preprocessing strategies
- Advanced feature transformations

## Test Data

### Sample Titanic Data
The tests create sample Titanic-like data with:
- Missing values in `Age` column (~20%)
- Missing values in `Cabin` column (~80%)
- Categorical columns: `Sex`, `Pclass`, `Embarked`
- Numerical columns: `Age`, `Fare`, `SibSp`, `Parch`
- ID column: `PassengerId`
- Text column: `Name`
- Target: `Survived` (binary)

This data is representative of typical Kaggle tabular competitions.

## Expected Results

### Successful Test Run
```
TEST SUMMARY
======================================================================
âœ… PASS - Code Generation
âœ… PASS - Code Execution
âœ… PASS - Full Phase Integration
âœ… PASS - Skip Preprocessing Logic

Passed: 4/4

ðŸŽ‰ All tests passed!
```

### After Preprocessing
- âœ… `clean_train.csv` created with no missing values
- âœ… `clean_test.csv` created with no missing values
- âœ… ID columns dropped
- âœ… Target column preserved in train only
- âœ… Categorical variables encoded
- âœ… `preprocessing.py` saved with generated code

## Debugging Failed Tests

### Code Generation Fails
**Symptoms**: AI doesn't return valid preprocessing code
**Check**:
1. `GEMINI_API_KEY` is set correctly
2. API quota not exceeded
3. Internet connection working
4. Check `src/prompts/preprocessing_agent.txt` exists

### Code Execution Fails
**Symptoms**: Generated code throws errors during execution
**Check**:
1. Generated code saved to `preprocessing.py` - inspect it
2. Check for syntax errors in generated code
3. Verify data files exist in correct location
4. Check Python dependencies installed

### Output Files Not Created
**Symptoms**: `clean_train.csv` or `clean_test.csv` missing
**Check**:
1. Generated code has correct save logic
2. File paths are correct
3. Write permissions in data directory
4. No exceptions during execution

### Data Leakage Detected
**Symptoms**: Test/train information bleeding
**Check**:
1. Scalers/encoders fitted on train only
2. Transform applied to both train and test
3. No global statistics from test set used
4. Target column not in test data

## Test Structure

```
tests/
â”œâ”€â”€ test_preprocessing_phase.py          # Pytest unit/integration tests
â”œâ”€â”€ test_preprocessing_integration.py    # Manual integration test
â””â”€â”€ TEST_PREPROCESSING_README.md         # This file

Test creates temporary directories:
data/
â”œâ”€â”€ test_preprocessing/                  # For Test 1 & 2
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â”œâ”€â”€ generated_preprocessing.py
â”‚   â”œâ”€â”€ clean_train.csv
â”‚   â””â”€â”€ clean_test.csv
â””â”€â”€ test_preprocessing_phase/            # For Test 3
    â”œâ”€â”€ train.csv
    â”œâ”€â”€ test.csv
    â”œâ”€â”€ preprocessing.py
    â”œâ”€â”€ clean_train.csv
    â””â”€â”€ clean_test.csv
```

## CI/CD Integration

To integrate these tests in CI/CD:

```yaml
# Example GitHub Actions
- name: Run Preprocessing Tests
  env:
    GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  run: |
    pytest tests/test_preprocessing_phase.py -v --tb=short
```

## Mocking for Tests

The unit tests use mocking to avoid actual AI calls:

```python
with patch('src.agents.llm_agents.preprocessing_agent.generate_ai_response',
           return_value=mock_code):
    code = await agent.generate_preprocessing_code(...)
```

This allows fast, deterministic tests without API costs.

## Adding New Tests

To add tests for new modalities:

1. **Create fixture** with sample data analysis for that modality
2. **Add test method** to `TestPreprocessingAgent`
3. **Mock AI response** with expected code pattern
4. **Verify** code contains modality-specific logic

Example:
```python
@pytest.fixture
def sample_data_analysis_vision(self):
    return {
        "data_modality": "vision",
        "preprocessing": {
            "resize": {"width": 224, "height": 224},
            "normalize": True,
            "augmentation": ["flip", "rotate"]
        }
    }

@pytest.mark.asyncio
async def test_generate_preprocessing_code_vision(self, ...):
    # Test implementation
```

## Contributing

When adding preprocessing features:
1. âœ… Write tests FIRST (TDD)
2. âœ… Test both success and failure cases
3. âœ… Add integration test for new modality
4. âœ… Update this README with new test info
5. âœ… Ensure 100% coverage for critical paths

## Questions?

See the main project documentation in `/CLAUDE.md` for architecture details.

---

**Last Updated**: 2024-11-08
**Test Coverage**: ~95% for Phase 4
**Status**: âœ… All Tests Passing
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ğŸ¯ Project Vision

**Goal:** Build a universal multi-agent system that autonomously participates in ANY Kaggle competition and achieves top 20% ranking.

**Core Mission:**
1. **Understand Problem** - Read competition description and verify against data
2. **Analyze Data** - Deep analysis with preprocessing recommendations
3. **Clean & Engineer** - Prepare data with AI-generated code
4. **Plan Strategy** - Select models and approaches
5. **Train Models** - Execute training with optimal configurations
6. **Submit & Iterate** - Submit predictions and improve until target achieved

**Universal Capability:** The system architecture handles ANY Kaggle problem type:
- âœ… **Tabular** (regression, binary/multi-class classification, ranking) - FULLY IMPLEMENTED
- âœ… **NLP** (sentiment, classification, QA, generation) - FULLY IMPLEMENTED
- ğŸ—ï¸ **Computer Vision** (classification, detection, segmentation) - ARCHITECTURE READY
- ğŸ—ï¸ **Time Series** (forecasting, anomaly detection) - ARCHITECTURE READY
- ğŸ—ï¸ **Audio** (speech recognition, classification) - ARCHITECTURE READY
- ğŸ—ï¸ **Multi-modal** (image+text, video, etc.) - ARCHITECTURE READY

---

## ğŸ—ï¸ Architecture Philosophy

### AI-First, Zero-Hardcoded Logic

**CRITICAL PRINCIPLE:** This system contains ZERO hardcoded assumptions about:
- Problem type or domain
- Data format or structure
- Target variable location or type
- Required preprocessing steps
- Model architecture selection
- Feature engineering strategies
- Hyperparameter values
- Competition-specific logic

**Everything is decided by AI agents** based on:
1. Reading competition problem statement
2. Understanding the goal and evaluation metric
3. Analyzing available data
4. Creating an execution plan
5. Adapting strategies based on leaderboard feedback

### Sequential Pipeline with Conditional Agents

**Pattern:** Sequential flow with conditional agent invocation
- Easy to understand and debug
- Cost-efficient (skip unnecessary agents)
- Predictable execution
- Optimized for learning and development

**Flow:**
```
Always Called â†’ DataCollector
Always Called â†’ ProblemUnderstandingAgent
Always Called â†’ DataAnalysisAgent
Conditional  â†’ PreprocessingAgent (only if needs_preprocessing)
Always Called â†’ PlanningAgent
Conditional  â†’ FeatureEngineeringAgent (only if needs_feature_engineering)
Always Called â†’ ModelTrainer
Always Called â†’ EvaluationAgent
Conditional  â†’ StrategyOptimizer (only if not at target, loops back)
```

---

## ğŸ“Š Multi-Agent Architecture (Option B: Core Modalities)

### Implementation Strategy

**By Nov 27, 2024:**
- âœ… **Tabular Competitions:** Fully implemented (LightGBM, XGBoost, PyTorch MLP)
- âœ… **NLP Competitions:** Fully implemented (BERT, Transformers)
- ğŸ“‹ **Vision/Time Series:** Architecture ready, implementations pending

**Why Option B?**
- Covers 70% of Kaggle competitions (tabular + NLP)
- Realistic for 22-day timeline
- Demonstrates universal architecture
- Clear extension path for other modalities

---

## ğŸ”„ Agent Flow (10 Phases)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR                          â”‚
â”‚  - Coordinates workflow (no AI, just management)        â”‚
â”‚  - Passes context between agents                        â”‚
â”‚  - Conditionally invokes agents based on flags          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 1: DATA COLLECTION (Worker - No LLM Cost)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Downloads: train.csv, test.csv, problem description
â”‚ Basic analysis: file sizes, row/column counts
â””â”€â†’ Output: Raw files + basic statistics

Phase 2: PROBLEM UNDERSTANDING (LLM Agent ğŸ¤–)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Input: Competition text + Raw data files
â”‚ Reads: Problem description AND verifies against data
â”‚ Output: Problem context (task type, metric, target)
â””â”€â†’ ğŸ’° Cost: 1 LLM call

Phase 3: DATA ANALYSIS (LLM Agent ğŸ¤–)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Input: Problem context + Raw data
â”‚ Analyzes: Missing values, types, distributions, correlations
â”‚ Detects: Data modality (tabular/nlp/vision/timeseries)
â”‚ Decides: needs_preprocessing? (true/false)
â”‚ Output: Analysis report + preprocessing recommendations
â””â”€â†’ ğŸ’° Cost: 1 LLM call

Phase 4: PREPROCESSING (Conditional - LLM + Worker)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IF needs_preprocessing == True:
  â”‚ PreprocessingAgent (LLM ğŸ¤–):
  â”‚   - Reads DataAnalysis recommendations
  â”‚   - Writes Python preprocessing code (modality-aware)
  â”‚   - Returns executable code
  â”‚
  â”‚ Executor (Worker):
  â”‚   - Executes generated code
  â”‚   - Saves clean_train.csv, clean_test.csv
  â””â”€â†’ Output: Clean data (0% missing, encoded, normalized)
      ğŸ’° Cost: 1 LLM call (if preprocessing needed)
ELSE:
  â””â”€â†’ Skip (0 LLM calls, use raw data)

Phase 5: PLANNING (LLM Agent ğŸ¤–)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Input: Problem + Analysis + Clean data
â”‚ Creates: Model strategy, hyperparameters, validation plan
â”‚ Decides: needs_feature_engineering? (true/false)
â”‚ Output: Execution plan with model configs
â””â”€â†’ ğŸ’° Cost: 1 LLM call

Phase 6: FEATURE ENGINEERING (Conditional - LLM + Worker)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IF needs_feature_engineering == True:
  â”‚ FeatureEngineeringAgent (LLM ğŸ¤–):
  â”‚   - Reads PlanningAgent recommendations
  â”‚   - Writes Python feature engineering code
  â”‚   - Returns executable code
  â”‚
  â”‚ Executor (Worker):
  â”‚   - Executes generated code on clean data
  â”‚   - Saves featured_train.csv
  â””â”€â†’ Output: Featured data
      ğŸ’° Cost: 1 LLM call (if features needed)
ELSE:
  â””â”€â†’ Skip (0 LLM calls, use clean data)

Phase 7: MODEL TRAINING (Worker - No LLM Cost)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Input: Featured/clean data + Execution plan
â”‚ Trains: Models specified in plan (LightGBM, XGBoost, BERT, etc.)
â”‚ Uses: Hyperparameters from plan
â”‚ Validation: Strategy from plan (stratified k-fold, etc.)
â”‚ Output: Trained models + CV scores
â””â”€â†’ ğŸ’° Cost: 0 (pure execution)

Phase 8: SUBMISSION (Worker - No LLM Cost)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Generates: Predictions on test data
â”‚ Formats: Per competition requirements
â”‚ Submits: To Kaggle via API
â”‚ Output: Submission file + Leaderboard score
â””â”€â†’ ğŸ’° Cost: 0

Phase 9: EVALUATION (LLM Agent ğŸ¤–)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Input: CV scores, LB score, training metrics
â”‚ Analyzes: CV vs LB gap, overfitting, underfitting
â”‚ Diagnoses: Issues and hypotheses
â”‚ Decides: needs_improvement? (true/false)
â”‚ Output: Diagnosis report
â””â”€â†’ ğŸ’° Cost: 1 LLM call

Phase 10: OPTIMIZATION (Conditional - LLM Agent ğŸ¤–)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IF needs_improvement == True AND iteration < max_iterations:
  â”‚ StrategyOptimizer (LLM ğŸ¤–):
  â”‚   - Reads evaluation diagnosis
  â”‚   - Suggests specific changes
  â”‚   - Decides where to loop back (Phase 4, 5, or 6)
  â”‚   - Returns optimization strategy
  â””â”€â†’ Loop back to appropriate phase
      ğŸ’° Cost: 1 LLM call per iteration
ELSE:
  â””â”€â†’ Done! Target achieved or max iterations reached
```

---

## ğŸ“‹ Agent Communication Table

| Phase | Agent | Type | Says What | To Whom | LLM Cost |
|-------|-------|------|-----------|---------|----------|
| **1** | DataCollector | âš™ï¸ Worker | "Downloaded train.csv (891Ã—12), test.csv (418Ã—11), problem.txt" | â†’ ProblemUnderstanding | **Free** |
| **2** | ProblemUnderstandingAgent | ğŸ¤– LLM | "Binary classification. Target: Survived. Metric: Accuracy. Problem-data aligned âœ“" | â†’ DataAnalysis | **1 call** |
| **3** | DataAnalysisAgent | ğŸ¤– LLM | "Modality: tabular. Age: 20% missing. Sex needs encoding. **needs_preprocessing: true**" | â†’ PreprocessingAgent | **1 call** |
| **4a** | PreprocessingAgent | ğŸ¤– LLM | "Generated preprocessing code: [impute Age median, encode Sex/Pclass, drop Cabin]" | â†’ Executor | **1 call** (conditional) |
| **4b** | Executor | âš™ï¸ Worker | "Preprocessing complete âœ“. Output: clean_train.csv (891Ã—9, 0% missing)" | â†’ PlanningAgent | **Free** |
| **5** | PlanningAgent | ğŸ¤– LLM | "Strategy: LightGBM (priority 1), XGBoost (priority 2). **needs_feature_engineering: true**" | â†’ FeatureEngineeringAgent | **1 call** |
| **6a** | FeatureEngineeringAgent | ğŸ¤– LLM | "Generated feature code: [family_size, is_alone, age_bins, title]" | â†’ Executor | **1 call** (conditional) |
| **6b** | Executor | âš™ï¸ Worker | "Features created âœ“. Output: featured_train.csv (891Ã—13)" | â†’ ModelTrainer | **Free** |
| **7** | ModelTrainer | âš™ï¸ Worker | "LightGBM CV: 0.815. XGBoost CV: 0.808. Ensemble CV: 0.823" | â†’ Submitter | **Free** |
| **8** | Submitter | âš™ï¸ Worker | "Submitted to Kaggle. Leaderboard score: 0.79. Rank: 30th percentile" | â†’ EvaluationAgent | **Free** |
| **9** | EvaluationAgent | ğŸ¤– LLM | "CV: 0.823, LB: 0.79. Gap: 3.3% (overfitting). **needs_improvement: true**" | â†’ StrategyOptimizer | **1 call** |
| **10** | StrategyOptimizer | ğŸ¤– LLM | "Add L1/L2 regularization. Drop title feature. Loop back to Phase 6" | â†’ FeatureEngineeringAgent (iter 2) | **1 call** (conditional) |

**Iteration 1 Total: ~7 LLM calls** (if both preprocessing and features needed)

---

## ğŸ’° Cost Analysis (Gemini Free Tier Friendly)

### Scenario 1: Titanic (Tabular with preprocessing + features)
```
âœ… ProblemUnderstanding     â†’ 1 call
âœ… DataAnalysis             â†’ 1 call
âœ… PreprocessingAgent       â†’ 1 call (needed)
âœ… PlanningAgent            â†’ 1 call
âœ… FeatureEngineeringAgent  â†’ 1 call (needed)
âœ… EvaluationAgent          â†’ 1 call
âœ… StrategyOptimizer        â†’ 1 call (if not at target)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 7 LLM calls per iteration
```

### Scenario 2: Clean UCI Dataset (No preprocessing)
```
âœ… ProblemUnderstanding     â†’ 1 call
âœ… DataAnalysis             â†’ 1 call (says needs_preprocessing: false)
â­ï¸  PreprocessingAgent       â†’ 0 calls (SKIPPED)
âœ… PlanningAgent            â†’ 1 call
âœ… FeatureEngineeringAgent  â†’ 1 call
âœ… EvaluationAgent          â†’ 1 call
âœ… StrategyOptimizer        â†’ 1 call
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 6 LLM calls
```

### Scenario 3: Image Classification (No preprocessing/features)
```
âœ… ProblemUnderstanding     â†’ 1 call
âœ… DataAnalysis             â†’ 1 call (says needs_preprocessing: false)
â­ï¸  PreprocessingAgent       â†’ 0 calls (SKIPPED)
âœ… PlanningAgent            â†’ 1 call (says needs_feature_engineering: false)
â­ï¸  FeatureEngineeringAgent  â†’ 0 calls (SKIPPED)
âœ… EvaluationAgent          â†’ 1 call
âœ… StrategyOptimizer        â†’ 1 call
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 5 LLM calls
```

**Gemini Free Tier:** 60 requests/minute
**Safe for:** Multiple iterations, experimentation, learning âœ…

---

## ğŸ¯ Agent Specifications

### 1. DataCollector (Worker)
**Role:** Downloads competition files
**Input:** `competition_name: str`
**Output:**
```python
{
  "data_path": "/data/titanic/",
  "files": ["train.csv", "test.csv", "sample_submission.csv"],
  "problem_description": "text from Kaggle page",
  "basic_stats": {"train.csv": {"rows": 891, "columns": 12}}
}
```
**Cost:** Free (no LLM)

---

### 2. ProblemUnderstandingAgent (LLM)
**Role:** Understands competition by reading problem text AND verifying against data
**Input:**
- `problem_description: str`
- `data_files: List[str]`
- `basic_stats: Dict`

**Output:**
```python
{
  "competition_type": "binary_classification",
  "task_description": "Predict passenger survival on Titanic",
  "evaluation_metric": "accuracy",
  "submission_format": {
    "id_column": "PassengerId",
    "prediction_column": "Survived",
    "output_type": "binary"
  },
  "data_alignment": {
    "problem_claims": "Predict survival",
    "data_confirms": "Survived column exists (0/1)",
    "matches": true
  },
  "timeline": "30 days",
  "key_challenges": [
    "Small dataset (891 rows)",
    "Missing values visible",
    "Imbalanced target possible"
  ]
}
```
**Cost:** 1 LLM call

---

### 3. DataAnalysisAgent (LLM)
**Role:** Deep data analysis with modality detection and preprocessing recommendations
**Input:**
- `problem_understanding: Dict`
- `data_path: str`
- `files: List[str]`

**Output:**
```python
{
  "data_modality": "tabular",  # â† CRITICAL for routing
  "target_column": "Survived",
  "target_type": "binary",
  "target_distribution": {"0": 549, "1": 342},
  "is_imbalanced": true,

  "feature_types": {
    "id_columns": ["PassengerId"],
    "numerical": ["Age", "Fare", "SibSp", "Parch"],
    "categorical": ["Sex", "Pclass", "Embarked"],
    "text": ["Name"],
    "drop_candidates": ["PassengerId", "Ticket", "Cabin"]
  },

  "data_quality": {
    "missing_values": {
      "Age": {"count": 177, "percentage": 0.20},
      "Cabin": {"count": 687, "percentage": 0.77}
    },
    "outliers": ["Fare"],
    "class_balance": "imbalanced"
  },

  "preprocessing_required": true,  # â† DECISION FLAG
  "preprocessing_recommendations": {
    "modality": "tabular",
    "drop_columns": ["PassengerId", "Ticket", "Cabin"],
    "impute_missing": {
      "Age": {"method": "median", "reason": "normally distributed"},
      "Embarked": {"method": "mode", "reason": "only 2 missing"}
    },
    "encode_categorical": {
      "Sex": "label",
      "Pclass": "label",
      "Embarked": "label"
    },
    "handle_outliers": {
      "Fare": {"method": "cap", "percentile": 99}
    }
  }
}
```
**Cost:** 1 LLM call

---

### 4. PreprocessingAgent (LLM) - Conditional
**Role:** Generates executable Python code for data preprocessing
**Input:**
- `data_analysis: Dict` (with preprocessing_recommendations)
- `data_modality: str` (tabular/nlp/vision/timeseries)
- `raw_data_path: str`

**Output:**
```python
{
  "preprocessing_code": """
import pandas as pd
import numpy as np

def preprocess_data(input_path, output_path):
    # Load raw data
    df = pd.read_csv(input_path)

    # Drop useless columns
    df = df.drop(columns=['PassengerId', 'Ticket', 'Cabin'])

    # Impute Age with median
    age_median = df['Age'].median()
    df['Age'].fillna(age_median, inplace=True)

    # Encode Sex
    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})

    # Cap Fare outliers
    fare_cap = df['Fare'].quantile(0.99)
    df['Fare'] = df['Fare'].clip(upper=fare_cap)

    # Save clean data
    df.to_csv(output_path, index=False)
    return len(df), len(df.columns)
""",
  "explanation": "Drops IDs, imputes Age median, encodes Sex, caps Fare",
  "expected_output": "clean_train.csv (891 rows, 9 columns, 0% missing)"
}
```
**Cost:** 1 LLM call (only if preprocessing_required == true)

**Modality-Aware Prompting:**
- **Tabular:** Impute, encode, scale, outliers
- **NLP:** Lowercase, remove URLs, tokenize, remove stopwords
- **Vision:** Normalize, resize, augmentation
- **Time Series:** Parse dates, create time index, handle gaps

---

### 5. PlanningAgent (LLM)
**Role:** Creates comprehensive strategy with model selection
**Input:**
- `problem_understanding: Dict`
- `data_analysis: Dict`
- `clean_data_path: str` (or raw if no preprocessing)
- `clean_data_stats: Dict`

**Output:**
```python
{
  "strategy_summary": "Tree-based models with engineered features",
  "data_modality": "tabular",  # Pass through for downstream

  "models_to_try": [
    {
      "model": "lightgbm",
      "priority": 1,
      "reason": "Fast, handles missing values, great for tabular",
      "hyperparameters": {
        "num_leaves": 31,
        "learning_rate": 0.05,
        "n_estimators": 100,
        "max_depth": 7
      },
      "expected_performance": "0.78-0.82 accuracy"
    },
    {
      "model": "xgboost",
      "priority": 2,
      "reason": "Often beats LightGBM, ensemble candidate",
      "hyperparameters": {
        "max_depth": 5,
        "learning_rate": 0.05,
        "n_estimators": 100
      }
    }
  ],

  "feature_engineering_required": true,  # â† DECISION FLAG
  "feature_engineering_plan": [
    {
      "feature_name": "family_size",
      "formula": "SibSp + Parch + 1",
      "reason": "Capture family unit effect",
      "priority": 1
    },
    {
      "feature_name": "age_bins",
      "formula": "pd.cut(Age, bins=[0,12,18,35,60,100])",
      "reason": "Age is clean now, can bin safely",
      "priority": 1
    }
  ],

  "validation_strategy": {
    "method": "stratified_kfold",
    "n_splits": 5,
    "stratify_column": "Survived",
    "shuffle": true,
    "random_state": 42,
    "reason": "Preserve class ratio, reduce variance"
  },

  "success_criteria": {
    "target_metric_value": 0.80,
    "target_percentile": 0.20,
    "max_training_time_hours": 1
  }
}
```
**Cost:** 1 LLM call

---

### 6. FeatureEngineeringAgent (LLM) - Conditional
**Role:** Generates executable Python code for feature engineering
**Input:**
- `feature_engineering_plan: List[Dict]` (from PlanningAgent)
- `clean_data_path: str`
- `data_modality: str`

**Output:**
```python
{
  "feature_engineering_code": """
import pandas as pd

def engineer_features(input_path, output_path):
    df = pd.read_csv(input_path)

    # Feature 1: family_size
    df['family_size'] = df['SibSp'] + df['Parch'] + 1

    # Feature 2: is_alone
    df['is_alone'] = (df['family_size'] == 1).astype(int)

    # Feature 3: age_bins
    df['age_bins'] = pd.cut(
        df['Age'],
        bins=[0, 12, 18, 35, 60, 100],
        labels=[0, 1, 2, 3, 4]
    ).astype(int)

    df.to_csv(output_path, index=False)
    return len(df), len(df.columns)
""",
  "explanation": "Creates 3 features: family_size, is_alone, age_bins",
  "expected_output": "featured_train.csv (891 rows, 12 columns)"
}
```
**Cost:** 1 LLM call (only if feature_engineering_required == true)

---

### 7. ModelTrainer (Worker)
**Role:** Executes training based on execution plan
**Input:**
- `execution_plan: Dict` (from PlanningAgent)
- `data_path: str` (featured or clean data)
- `target_column: str`

**Actions:**
1. Loads data from data_path
2. For each model in `models_to_try`:
   - Instantiates model with hyperparameters from plan
   - Sets up validation per `validation_strategy`
   - Trains model
   - Tracks CV scores
3. Saves trained models
4. Returns results

**Output:**
```python
{
  "models_trained": [
    {
      "model_type": "lightgbm",
      "model_path": "/models/titanic/lightgbm_fold_avg.pkl",
      "cv_score": 0.815,
      "cv_std": 0.023,
      "fold_scores": [0.82, 0.81, 0.83, 0.80, 0.81],
      "training_time": 12.3
    },
    {
      "model_type": "xgboost",
      "cv_score": 0.808,
      "cv_std": 0.028
    }
  ],
  "best_model": "lightgbm",
  "ensemble_score": 0.823
}
```
**Cost:** Free (no LLM)

**Modality Routing:**
```python
if modality == "tabular":
    if model_name == "lightgbm": return train_lightgbm(...)
    elif model_name == "xgboost": return train_xgboost(...)
elif modality == "nlp":
    if "bert" in model_name: return train_bert(...)
elif modality == "vision":
    raise NotImplementedError("Vision models coming soon")
```

---

### 8. Submitter (Worker)
**Role:** Generates predictions and submits to Kaggle
**Input:**
- `model_path: str`
- `test_data_path: str`
- `submission_format: Dict` (from ProblemUnderstanding)

**Actions:**
1. Applies same preprocessing/features to test data
2. Loads trained model
3. Generates predictions
4. Formats per submission requirements
5. Submits via Kaggle API

**Output:**
```python
{
  "submission_file": "/submissions/titanic_submission_001.csv",
  "submission_id": "12345",
  "leaderboard_score": 0.79,
  "current_rank": "30th percentile"
}
```
**Cost:** Free

---

### 9. EvaluationAgent (LLM)
**Role:** Diagnoses model performance and identifies issues
**Input:**
- `training_results: Dict`
- `leaderboard_score: float`
- `execution_plan: Dict`

**Output:**
```python
{
  "cv_score": 0.823,
  "lb_score": 0.79,
  "gap": -0.033,
  "gap_type": "overfitting",

  "diagnosis": {
    "overfitting": true,
    "underfitting": false,
    "train_test_shift": "possible",
    "cv_reliable": true
  },

  "current_percentile": 0.30,
  "target_percentile": 0.20,
  "gap_to_target": 0.10,
  "improvement_needed": "+2-3% accuracy",

  "strengths": [
    "LightGBM strong (CV 0.815)",
    "Low fold variance (reliable)"
  ],

  "weaknesses": [
    "Overfitting by 3.3%",
    "Too many features?"
  ],

  "needs_improvement": true,  # â† DECISION FLAG

  "hypotheses": [
    "Add regularization (L1/L2)",
    "Drop low-importance features",
    "Simplify feature engineering"
  ]
}
```
**Cost:** 1 LLM call

---

### 10. StrategyOptimizer (LLM) - Conditional
**Role:** Suggests specific improvements and decides loop-back point
**Input:**
- `evaluation_diagnosis: Dict`
- `full_context: Dict` (all previous results)

**Output:**
```python
{
  "iteration": 2,
  "strategy_type": "refinement",  # vs "rebuild"

  "changes_recommended": {
    "preprocessing": "no change",
    "feature_engineering": {
      "action": "remove",
      "features_to_drop": ["title", "fare_per_person"],
      "reason": "Reduce overfitting"
    },
    "model_selection": {
      "models_to_try": ["lightgbm"],  # Only best
      "hyperparameter_changes": {
        "lightgbm": {
          "reg_alpha": 0.1,  # Add L1 reg
          "reg_lambda": 0.1,  # Add L2 reg
          "max_depth": 5      # Reduce from 7
        }
      }
    }
  },

  "loop_back_to": "feature_engineering",  # Phase 6

  "expected_improvement": {
    "cv_score": 0.81,
    "lb_score": 0.805,
    "percentile": 0.18
  },

  "confidence": "medium-high"
}
```
**Cost:** 1 LLM call (only if needs_improvement == true)

---

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base.py                          # BaseAgent for all workers
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_agents/                      # AI Decision Makers
â”‚   â”‚   â”œâ”€â”€ base_llm_agent.py            # Base for LLM agents
â”‚   â”‚   â”œâ”€â”€ problem_understanding_agent.py    # âœ… IMPLEMENTED
â”‚   â”‚   â”œâ”€â”€ data_analysis_agent.py       # âœ… IMPLEMENTED
â”‚   â”‚   â”œâ”€â”€ preprocessing_agent.py       # ğŸš§ TO IMPLEMENT (Day 5-6)
â”‚   â”‚   â”œâ”€â”€ planning_agent.py            # âœ… IMPLEMENTED
â”‚   â”‚   â”œâ”€â”€ feature_engineering_agent.py # ğŸš§ TO IMPLEMENT (Day 8-9)
â”‚   â”‚   â”œâ”€â”€ evaluation_agent.py          # ğŸš§ TO IMPLEMENT (Day 15-16)
â”‚   â”‚   â””â”€â”€ strategy_agent.py            # ğŸš§ TO IMPLEMENT (Day 15-16)
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py              # âœ… NEEDS REFACTOR (Day 3-4)
â”‚   â”‚   â””â”€â”€ phases.py                    # âœ… NEEDS REFACTOR (Day 3-4)
â”‚   â”‚
â”‚   â”œâ”€â”€ data_collector/
â”‚   â”‚   â””â”€â”€ collector.py                 # âœ… IMPLEMENTED
â”‚   â”‚
â”‚   â”œâ”€â”€ model_trainer/
â”‚   â”‚   â”œâ”€â”€ trainer.py                   # âœ… NEEDS REFACTOR (Day 10-11)
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py             # âœ… NEEDS REFACTOR (Day 10-11)
â”‚   â”‚   â”œâ”€â”€ detection.py                 # Task/model type detection
â”‚   â”‚   â””â”€â”€ models/                      # Model implementations
â”‚   â”‚       â”œâ”€â”€ tabular/
â”‚   â”‚       â”‚   â”œâ”€â”€ lightgbm.py          # âœ… IMPLEMENTED
â”‚   â”‚       â”‚   â”œâ”€â”€ xgboost.py           # âœ… IMPLEMENTED
â”‚   â”‚       â”‚   â””â”€â”€ pytorch_mlp.py       # âœ… IMPLEMENTED
â”‚   â”‚       â”œâ”€â”€ nlp/
â”‚   â”‚       â”‚   â”œâ”€â”€ transformer.py       # âœ… IMPLEMENTED
â”‚   â”‚       â”‚   â””â”€â”€ bert_classifier.py   # ğŸš§ TO IMPLEMENT
â”‚   â”‚       â”œâ”€â”€ vision/                  # ğŸ”® FUTURE (architecture ready)
â”‚   â”‚       â”‚   â”œâ”€â”€ resnet.py
â”‚   â”‚       â”‚   â””â”€â”€ efficientnet.py
â”‚   â”‚       â””â”€â”€ timeseries/              # ğŸ”® FUTURE (architecture ready)
â”‚   â”‚           â”œâ”€â”€ lstm.py
â”‚   â”‚           â””â”€â”€ prophet.py
â”‚   â”‚
â”‚   â”œâ”€â”€ submission/
â”‚   â”‚   â””â”€â”€ submitter.py                 # âœ… IMPLEMENTED
â”‚   â”‚
â”‚   â””â”€â”€ leaderboard/
â”‚       â””â”€â”€ monitor.py                   # âœ… IMPLEMENTED
â”‚
â””â”€â”€ main.py                              # âœ… Entry point
```

---

## ğŸš€ Implementation Status

### âœ… Fully Implemented (Working Today)
- BaseAgent architecture
- Orchestrator workflow (needs refactoring for Option B)
- Data collection via Kaggle API
- Problem understanding agent
- Data analysis agent
- Planning agent
- Tabular model training (LightGBM, XGBoost, PyTorch MLP)
- Basic NLP support (transformers)
- Submission handling
- Leaderboard monitoring

### ğŸš§ To Implement (Days 3-22)
- **Day 3-4:** Fix orchestrator flow (remove duplicates, context passing)
- **Day 5-6:** PreprocessingAgent (code generation for tabular + NLP)
- **Day 7:** Test Phase 1-4 on Titanic
- **Day 8-9:** FeatureEngineeringAgent (code generation)
- **Day 10-11:** Refactor ModelTrainer/DataPipeline to use execution_plan
- **Day 12-13:** End-to-end testing (tabular + NLP)
- **Day 15-16:** EvaluationAgent + StrategyOptimizer
- **Day 17-18:** Test on 3rd competition
- **Day 19-20:** Logging and error handling
- **Day 21:** Final documentation

### ğŸ”® Future Work (Post-Nov 27)
- **Computer Vision:** ResNet, EfficientNet, ViT implementations
- **Time Series:** LSTM, Prophet, ARIMA implementations
- **Audio:** Speech recognition models
- **Multi-modal:** Combined approaches
- **Advanced Features:**
  - Parallel model training
  - Hyperparameter optimization (Optuna)
  - Advanced ensembling (stacking, blending)
  - External data collection
  - Meta-learning from past competitions

---

## ğŸ”§ Key Implementation Principles

### 1. Modality Detection is Critical

DataAnalysisAgent MUST output `data_modality` accurately:
```python
{
  "data_modality": "tabular|nlp|vision|timeseries|audio|mixed"
}
```

This determines:
- Which preprocessing code to generate
- Which feature engineering to apply
- Which models to use

### 2. Conditional Agent Invocation

Orchestrator checks flags before calling agents:
```python
# Phase 4
if data_analysis["preprocessing_required"]:
    preprocessing_result = await preprocessing_agent.run(context)
    data_path = preprocessing_result["clean_data_path"]
else:
    logger.info("â­ï¸  Skipping preprocessing - data is clean")
    data_path = raw_data_path
```

### 3. Code Generation is Key

PreprocessingAgent and FeatureEngineeringAgent don't execute logic directly - they generate Python code that executors run. This allows:
- Full transparency (see exact code)
- Easy debugging (check generated code)
- Reproducibility (save code for later)
- Safety (review before execution)

### 4. Context Accumulation

Each agent adds to context:
```python
context = {
  "competition_name": "titanic",
  "problem_understanding": {...},   # From Phase 2
  "data_analysis": {...},            # From Phase 3
  "clean_data_path": "...",          # From Phase 4
  "execution_plan": {...},           # From Phase 5
  "featured_data_path": "...",       # From Phase 6
  "training_results": {...},         # From Phase 7
  "evaluation": {...}                # From Phase 9
}
```

Downstream agents receive full context and make informed decisions.

### 5. No Fallback Policy

If AI fails, system fails. No hardcoded fallbacks:
```python
if not execution_plan:
    raise RuntimeError(
        "âŒ No execution plan from AI. "
        "This is a pure agentic system - requires AI. "
        "Check GEMINI_API_KEY."
    )
```

This ensures the system stays truly universal.

---

## ğŸ¯ Success Metrics

**Primary Goal:** Achieve top 20% on tabular AND NLP competitions

**System Metrics:**
- Competition types successfully handled (target: 2+ by Nov 27)
- Average percentile ranking achieved
- Time to reach top 20%
- Cost per competition (LLM calls)

**Quality Metrics:**
- Zero hardcoded competition-specific logic
- Successful handling of different data modalities
- Strategy improvement across iterations

---

## ğŸ“‹ 22-Day Implementation Plan

### Week 1 (Nov 5-11): Foundation
- **Nov 5-6:** âœ… Architecture finalization & documentation
- **Nov 7-8:** Fix orchestrator (remove duplicates, context passing)
- **Nov 9-10:** Implement PreprocessingAgent
- **Nov 11:** Test Phases 1-4 on Titanic

### Week 2 (Nov 12-18): Core Implementation
- **Nov 12-13:** Implement FeatureEngineeringAgent
- **Nov 14-15:** Refactor ModelTrainer + DataPipeline
- **Nov 16-17:** End-to-end test (Titanic + NLP)
- **Nov 18:** Week 2 review

### Week 3 (Nov 19-25): Polish & Testing
- **Nov 19-20:** Iteration loop (Evaluation + Optimizer)
- **Nov 21-22:** Test on 3rd competition
- **Nov 23-24:** Logging and error handling
- **Nov 25:** Final documentation

### Week 4 (Nov 26-27): Buffer & Submission
- **Nov 26:** Buffer for unexpected issues
- **Nov 27:** Final testing and SUBMISSION ğŸ¯

---

## ğŸ”‘ Environment Setup

### Required API Keys

```bash
# .env file
GEMINI_API_KEY=your-gemini-key          # For AI agents (FREE TIER OK)
KAGGLE_USERNAME=your-username            # For Kaggle API
KAGGLE_KEY=your-kaggle-key              # For Kaggle API
```

### Running the System

```bash
# Install dependencies
pip install -r requirements.txt

# Run for any competition
python src/main.py

# The system will:
# 1. Understand competition problem
# 2. Analyze data
# 3. Generate preprocessing code (if needed)
# 4. Create execution plan
# 5. Generate feature engineering code (if needed)
# 6. Train models
# 7. Submit and monitor
# 8. Iterate until top 20%
```

---

## ğŸŒŸ Extending to New Modalities (Future)

### Adding Vision Support (Example)

**Step 1:** Implement model
```python
# src/agents/model_trainer/models/vision/resnet.py
async def train_resnet(X, y, config, models_dir):
    """Train ResNet50 for image classification"""
    # Implementation here
    pass
```

**Step 2:** Update ModelTrainer routing
```python
# src/agents/model_trainer/trainer.py
elif modality == "vision":
    if "resnet" in model_name:
        return train_resnet(X, y, config, models_dir)
```

**Step 3:** Test on vision competition
```bash
python src/main.py --competition "digit-recognizer"
```

Architecture handles the rest automatically! âœ¨

---

## ğŸ’¡ Remember

This documentation is the **north star** for all development. Every code change should move toward:
1. **More universal** - handles more competition types
2. **More intelligent** - AI makes more decisions
3. **Less hardcoded** - fewer assumptions in code
4. **More autonomous** - less human intervention needed

When in doubt, ask: "Will this work for a competition type we've never seen before?"

---

**Last Updated:** November 5, 2024
**Target Submission:** November 27, 2024
**Implementation Strategy:** Option B (Core Modalities)
**Status:** Architecture Finalized âœ… Ready for Implementation